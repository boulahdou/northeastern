{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Value Iteration\n",
      "[0, 1, 2, 3, 4, 5, 0]\n",
      "[2.0, 3.0, 4.0, 3, 4, 5, 0]\n",
      "[3.0, 4.0, 4.0, 3.0, 4.0, 5.0, 0.0]\n",
      "[3.5, 4.0, 4.0, 3.0, 4.0, 5.0, 0.0]\n",
      "\n",
      "['PLAY', 'PLAY', 'PLAY', 'STOP', 'STOP', 'STOP', 'STOP']\n",
      "\n",
      "In state 0 the optimal action is PLAY with value 3.5\n",
      "In state 1 the optimal action is PLAY with value 4.0\n",
      "In state 2 the optimal action is PLAY with value 4.0\n",
      "In state 3 the optimal action is STOP with value 3.0\n",
      "In state 4 the optimal action is STOP with value 4.0\n",
      "In state 5 the optimal action is STOP with value 5.0\n",
      "In state DONE the optimal action is STOP with value 0.0\n"
     ]
    }
   ],
   "source": [
    "# Recall our Markov Decision Process (MDP) from last week:\n",
    "# +3 points for Heads, +1 point for Tails\n",
    "# Stop at any time and collect that many points as your payoff.\n",
    "# But if you get 6 or more points, your payoff is nothing.\n",
    "\n",
    "\n",
    "\n",
    "# List our States (S), Actions (A), and Discount Factor (Gamma)\n",
    "S = [0, 1, 2, 3, 4, 5, 'DONE']\n",
    "A = ['STOP', 'PLAY']\n",
    "Gamma = 1\n",
    "\n",
    "\n",
    "# Define the Transition function with three parameters:\n",
    "# current state (s), action (a), new state (n)\n",
    "def T(s,a,n):\n",
    "    if a=='STOP' and n=='DONE':\n",
    "        return 1\n",
    "    if a=='PLAY':\n",
    "        if s=='DONE':\n",
    "            if n=='DONE': return 1\n",
    "        else:\n",
    "            if n=='DONE':\n",
    "                if s==5: return 1\n",
    "                if s==4: return 0.5\n",
    "                if s==3: return 0.5\n",
    "            else:\n",
    "                if n-s == 1: return 0.5\n",
    "                if n-s == 3: return 0.5\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Define the Reward function with three parameters:\n",
    "# current state (s), action (a), new state (n)\n",
    "def R(s,a,n):\n",
    "    if a=='STOP' and n=='DONE':\n",
    "        if s in [0,1,2,3,4,5]: return s\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Define the Value Iteration table V[k][s] and the\n",
    "# Policy Iteration table P[k][s], with 101 rows\n",
    "V = [ [0 for s in S] for k in range(101)]\n",
    "P = [ ['' for s in S] for k in range(101)]\n",
    "\n",
    "\n",
    "# Use the Bellman Equation to determine Row k+1 of\n",
    "# tables V and P, using the information in Row k.\n",
    "\n",
    "for k in range(100):\n",
    "    for s in S:\n",
    "        \n",
    "        # Initialize bestValue and bestPolicy\n",
    "        bestValue=-1\n",
    "        bestPolicy='UNKNOWN'\n",
    "\n",
    "        # For each State-Action pair (s,a), determine Q(s,a) using the\n",
    "        # Bellman Equation by considering all new states n from state s.\n",
    "        \n",
    "        for a in A:\n",
    "            qValue = 0\n",
    "            for n in S:\n",
    "                qValue += T(s,a,n)*(R(s,a,n) + Gamma*V[k][S.index(n)])\n",
    "            if qValue > bestValue:\n",
    "                bestValue = qValue\n",
    "                bestPolicy = a\n",
    "                \n",
    "        V[k+1][S.index(s)]=bestValue\n",
    "        P[k+1][S.index(s)]=bestPolicy\n",
    "        \n",
    "        \n",
    "# Print the results of our Value iteration\n",
    "print(\"Results of Value Iteration\")\n",
    "x=1\n",
    "while V[x] != V[x-1]:\n",
    "    print(V[x])\n",
    "    x+=1\n",
    "    \n",
    "# Print the final (optimal) Policy\n",
    "print(\"\")\n",
    "print(P[x])\n",
    "\n",
    "# Output the results of our 100th iteration.\n",
    "print(\"\")\n",
    "for s in S:\n",
    "    i = S.index(s)\n",
    "    print(\"In state\", s, \"the optimal action is\", P[100][i], \"with value\", V[100][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
